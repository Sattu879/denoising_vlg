{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/OykIfjxHbtg+rfZNF7LX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sattu879/denoising_vlg/blob/main/image_denoising.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL4_4rQVd3qZ",
        "outputId": "7990e03a-a186-476c-dae3-fb457819abae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Current directory: /content/drive/My Drive/Colab Notebooks\n",
            "Current directory: /content/drive/My Drive/Colab Notebooks/Train\n",
            "'high' directory is located at: /content/drive/My Drive/Colab Notebooks/Train/high\n",
            "'low' directory is located at: /content/drive/My Drive/Colab Notebooks/Train/low\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Navigate to the current directory containing the notebook\n",
        "notebook_directory = '/content/drive/My Drive/Colab Notebooks'\n",
        "\n",
        "os.chdir(notebook_directory)\n",
        "\n",
        "# Verify the current directory\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "\n",
        "# Step 3: Define the directory path\n",
        "test_directory = 'Train'\n",
        "os.chdir(test_directory)\n",
        "\n",
        "# Verify the current directory\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "\n",
        "# Step 4: Define the paths to the high and low quality directories\n",
        "high_quality_dir = 'high'\n",
        "low_quality_dir = 'low'\n",
        "\n",
        "# Verify the directories exist\n",
        "if os.path.exists(high_quality_dir) and os.path.exists(low_quality_dir):\n",
        "    print(f\"'high' directory is located at: {os.path.abspath(high_quality_dir)}\")\n",
        "    print(f\"'low' directory is located at: {os.path.abspath(low_quality_dir)}\")\n",
        "else:\n",
        "    print(\"One or both of the directories do not exist. Please check the paths.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "high_quality_images = sorted(glob.glob(os.path.join(high_quality_dir, '*.png')))\n",
        "low_quality_images = sorted(glob.glob(os.path.join(low_quality_dir, '*.png')))\n",
        "\n",
        "assert len(high_quality_images) == len(low_quality_images), \"The number of images in both directories must be the same.\"\n",
        "\n",
        "\n",
        "print(f\"Found {len(high_quality_images)} high-quality images.\")\n",
        "print(f\"Found {len(low_quality_images)} low-quality images.\")\n",
        "\n",
        "# Function to load and pair images\n",
        "def load_image_pairs(high_quality_images, low_quality_images):\n",
        "    pairs = []\n",
        "    for hq_img_path, lq_img_path in zip(high_quality_images, low_quality_images):\n",
        "        hq_img = cv2.imread(hq_img_path, cv2.IMREAD_COLOR)\n",
        "        lq_img = cv2.imread(lq_img_path, cv2.IMREAD_COLOR)\n",
        "        if hq_img is None or lq_img is None:\n",
        "            print(f\"Error reading images: {hq_img_path}, {lq_img_path}\")\n",
        "        else:\n",
        "            pairs.append((hq_img, lq_img))\n",
        "    return pairs\n",
        "\n",
        "image_pairs = load_image_pairs(high_quality_images, low_quality_images)\n",
        "\n",
        "if len(image_pairs) == 0:\n",
        "    print(\"No image pairs were loaded. Check your file paths and image formats.\")\n",
        "else:\n",
        "    print(f\"Successfully loaded {len(image_pairs)} image pairs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp3eqh36iT2y",
        "outputId": "4ba7948f-9547-4a14-81d4-ff7bfdada6de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 485 high-quality images.\n",
            "Found 485 low-quality images.\n",
            "Successfully loaded 485 image pairs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "def normalize_image(image):\n",
        "    return image.astype(np.float32) / 255.0\n",
        "\n",
        "# Normalize all pairs\n",
        "normalized_pairs = [(normalize_image(hq), normalize_image(lq)) for hq, lq in image_pairs]\n",
        "\n",
        "print(f\"First normalized pair shapes: {normalized_pairs[0][0].shape}, {normalized_pairs[0][1].shape}\")\n",
        "\n",
        "high_quality_images, low_quality_images = zip(*normalized_pairs)\n",
        "\n",
        "hq_train, hq_test, lq_train, lq_test = train_test_split(\n",
        "    high_quality_images, low_quality_images, test_size=0.2, random_state=42)\n",
        "\n",
        "hq_train, hq_val, lq_train, lq_val = train_test_split(\n",
        "    hq_train, lq_train, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "hq_train, hq_val, hq_test = np.array(hq_train), np.array(hq_val), np.array(hq_test)\n",
        "lq_train, lq_val, lq_test = np.array(lq_train), np.array(lq_val), np.array(lq_test)\n",
        "\n",
        "print(\"Training set size:\", len(hq_train))\n",
        "print(\"Validation set size:\", len(hq_val))\n",
        "print(\"Test set size:\", len(hq_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fik_jUTBkAQ6",
        "outputId": "d0aadbca-7e16-4ebb-ea9d-88ec111487ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First normalized pair shapes: (400, 600, 3), (400, 600, 3)\n",
            "Training set size: 291\n",
            "Validation set size: 97\n",
            "Test set size: 97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ImagePairDataset(Dataset):\n",
        "    def __init__(self, hq_images, lq_images):\n",
        "        self.hq_images = hq_images\n",
        "        self.lq_images = lq_images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hq_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        hq_img = self.hq_images[idx]\n",
        "        lq_img = self.lq_images[idx]\n",
        "        hq_img = torch.from_numpy(hq_img.transpose((2, 0, 1)))\n",
        "        lq_img = torch.from_numpy(lq_img.transpose((2, 0, 1)))\n",
        "        return hq_img, lq_img\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 16\n",
        "train_dataset = ImagePairDataset(hq_train, lq_train)\n",
        "val_dataset = ImagePairDataset(hq_val, lq_val)\n",
        "test_dataset = ImagePairDataset(hq_test, lq_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "7cpwZGLqkFwX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class DenoisingCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DenoisingCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.conv3(x)\n",
        "        return x\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "6v5R6jirkqW2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model():\n",
        "    model = DenoisingCNN()\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    return model, criterion, optimizer\n"
      ],
      "metadata": {
        "id": "oPsRUZ5zkuUR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ImagePairDataset(Dataset):\n",
        "    def __init__(self, hq_images, lq_images):\n",
        "        self.hq_images = hq_images\n",
        "        self.lq_images = lq_images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hq_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        hq_img = self.hq_images[idx]\n",
        "        lq_img = self.lq_images[idx]\n",
        "        hq_img = torch.from_numpy(hq_img.transpose((2, 0, 1))).float()\n",
        "        lq_img = torch.from_numpy(lq_img.transpose((2, 0, 1))).float()\n",
        "        return hq_img, lq_img\n",
        "\n",
        "def create_dataloaders(hq_train, lq_train, hq_val, lq_val, batch_size=16):\n",
        "    train_dataset = ImagePairDataset(hq_train, lq_train)\n",
        "    val_dataset = ImagePairDataset(hq_val, lq_val)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "6wb3cTelkyFV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for inputs, targets in train_loader:\n",
        "            print('It is working')\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs_val, targets_val in val_loader:\n",
        "                inputs_val, targets_val = inputs_val.to(device), targets_val.to(device)\n",
        "                outputs_val = model(inputs_val)\n",
        "                loss = criterion(outputs_val, targets_val)\n",
        "                val_loss += loss.item() * inputs_val.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "    return model"
      ],
      "metadata": {
        "id": "igbjeGrMk8Hn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "train_loader, val_loader = create_dataloaders(hq_train, lq_train, hq_val, lq_val, batch_size=batch_size)\n",
        "\n",
        "model, criterion, optimizer = initialize_model()\n",
        "\n",
        "# Train the model\n",
        "trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=2)\n",
        "\n",
        "# Save the model\n",
        "torch.save(trained_model.state_dict(), '/content/denoising_model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqfQbjJfm61l",
        "outputId": "d017dab7-8572-4aef-94d7-870cf10f9a19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "Epoch [1/2], Train Loss: 0.0046, Val Loss: 0.0027\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "It is working\n",
            "Epoch [2/2], Train Loss: 0.0035, Val Loss: 0.0028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "model = DenoisingCNN()\n",
        "model.load_state_dict(torch.load('/content/denoising_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for inputs_test, targets_test in test_loader:\n",
        "        outputs_test = model(inputs_test.float())\n",
        "        loss = criterion(outputs_test, targets_test.float())\n",
        "        test_loss += loss.item() * inputs_test.size(0)\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "print(f'Test Loss: {test_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_gTo81WsftU",
        "outputId": "b52689f4-05cf-4401-e0db-be84b8fc9603"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "\n",
        "def calculate_metrics(denoised, original):\n",
        "    psnr_value = peak_signal_noise_ratio(original, denoised)\n",
        "    ssim_value, _ = structural_similarity(original, denoised, win_size=5, full=True, multichannel=True)\n",
        "    return psnr_value, ssim_value\n",
        "\n",
        "psnr_values = []\n",
        "ssim_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, (lq_tensor, original_img) in enumerate(test_loader):\n",
        "        denoised_tensor = model(lq_tensor.float())\n",
        "        denoised_img = denoised_tensor.squeeze().cpu().numpy()\n",
        "        original_img = original_img.squeeze().cpu().numpy()"
      ],
      "metadata": {
        "id": "dfqsK-agt7AJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage.transform\n",
        "\n",
        "denoised_img = skimage.transform.resize(denoised_img, (500, 700))\n",
        "original_img = skimage.transform.resize(original_img, (500, 700))"
      ],
      "metadata": {
        "id": "4hEqQU7Gumlq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "psnr_value, ssim_value = calculate_metrics(denoised_img, original_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4L3CqrBu0Bx",
        "outputId": "779b3963-7ec5-456f-cc71-6faef6c2d3a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-e67b27a94659>:5: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  ssim_value, _ = structural_similarity(original, denoised, win_size=5, full=True, multichannel=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "psnr_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3nwZClTvyXR",
        "outputId": "6c542f1c-b38c-423a-81d5-a0ae9781daea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.048402936932163"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ssim_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCZI2Rvnv9JH",
        "outputId": "fab7b094-d788-4d78-fca4-7e36e91fbbd9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9320107"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}